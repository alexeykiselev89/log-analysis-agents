import re
from typing import List, Dict
from collections import defaultdict
from datetime import datetime
from app.models.log_entry import LogEntry

LOG_PATTERN = re.compile(
    r'^(?P<timestamp>\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2},\d{3}) '
    r'\[(?P<level>[A-Z]+)\] '
    r'\[(?P<thread>[^\]]+)\] '
    r'(?P<class>[^\:]+): (?P<message>.+)$'
)

ERROR_LEVELS = {"ERROR", "WARN", "EXCEPTION"}

class LogParser:
    @staticmethod
    def parse_log(log_content: str) -> List[LogEntry]:
        entries = []
        buffer = ""
        last_entry = None

        lines = log_content.strip().splitlines()

        for i, line in enumerate(lines):
            line = line.strip()

            # –ï—Å–ª–∏ –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è –Ω–æ–≤–∞—è —Å—Ç—Ä–æ–∫–∞ –ª–æ–≥–∞
            match = LOG_PATTERN.match(line)
            if match:
                level = match.group("level").upper()
                if level not in ERROR_LEVELS:
                    continue

                if last_entry:
                    entries.append(last_entry)

                last_entry = LogEntry(
                    timestamp=datetime.strptime(match.group("timestamp"), "%Y-%m-%d %H:%M:%S,%f"),
                    level=level,
                    thread=match.group("thread"),
                    class_name=match.group("class"),
                    message=match.group("message").strip()
                )
            elif last_entry and (line.startswith("at ") or line.startswith("Caused by") or line.startswith("org.")):
                # –ü—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ –ø—Ä–µ–¥—ã–¥—É—â–µ–π –æ—à–∏–±–∫–∏ (stacktrace)
                last_entry.message += " " + line.strip()
            else:
                # –ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç ‚Äî –ø—Ä–æ–ø—É—Å–∫–∞–µ–º
                continue

        if last_entry:
            entries.append(last_entry)

        print(f"üîé [SUMMARY] –£—Å–ø–µ—à–Ω–æ —Ä–∞—Å–ø–∞—Ä—Å–µ–Ω–æ —Å—Ç—Ä–æ–∫: {len(entries)}")
        return entries

    @staticmethod
    def group_by_normalized_message(entries: List[LogEntry]) -> Dict[str, List[LogEntry]]:
        grouped = defaultdict(list)
        for entry in entries:
            normalized = LogParser.normalize_message(entry.message)
            if normalized.lower() == "–ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞":
                print(f"‚ö†Ô∏è  [SKIPPED] –°—Ç—Ä–æ–∫–∞ —Å–æ–¥–µ—Ä–∂–∏—Ç –æ–±–æ–±—â—ë–Ω–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ: {entry.message}")
                continue
            grouped[normalized].append(entry)
        return grouped

    @staticmethod
    def normalize_message(message: str) -> str:
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–µ—Ä–≤—ã–µ –∫–ª—é—á–µ–≤—ã–µ —Ñ—Ä–∞–∑—ã (–Ω–∞–ø—Ä–∏–º–µ—Ä, org.postgresql.PSQLException)
        preserved = ""
        if match := re.match(r'^(org\.[\w\.]+):', message):
            preserved = match.group(1)

        # –£–¥–∞–ª–µ–Ω–∏–µ ID, HASH, UUID –∏ —á–∏—Å–µ–ª
        message = re.sub(r'[a-fA-F0-9\-]{36}', '<UUID>', message)
        message = re.sub(r'\b\d{8,}\b', '<NUM>', message)
        message = re.sub(r'[a-fA-F0-9]{32,}', '<HASH>', message)
        message = re.sub(r'([a-zA-Z0-9_-]*id[a-zA-Z0-9_-]*)\s*=\s*[a-zA-Z0-9_-]+', r'\1=<ID>', message, flags=re.IGNORECASE)

        result = preserved + ": " + message if preserved else message
        return result.strip()
